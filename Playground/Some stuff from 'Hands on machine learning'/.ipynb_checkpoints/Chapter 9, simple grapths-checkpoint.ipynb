{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Широкий экран\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First graph and some types of initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up variables\n",
    "x = tf.Variable(3, name = 'x') #Any node is automatically added to the default graph!\n",
    "y = tf.Variable(4, name = 'y')\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# manually initialization\n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "sess.close()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# auto initiallization\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "sess.close()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# auto initialization with interactive session (only in Jupyter)\n",
    "# automatically percepts current session as default session\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "sess.close()\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression in tf**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without gradient descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Theta = (X^{T}\\cdot X)^{-1}\\cdot (X^{T}\\cdot y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7225266e+01]\n",
      " [ 4.3568176e-01]\n",
      " [ 9.3872147e-03]\n",
      " [-1.0598953e-01]\n",
      " [ 6.3939309e-01]\n",
      " [-4.1104349e-06]\n",
      " [-3.7780963e-03]\n",
      " [-4.2437303e-01]\n",
      " [-4.3785891e-01]]\n"
     ]
    }
   ],
   "source": [
    "# straightforward approach through normal equation without gradient descent\n",
    "# https://www.geeksforgeeks.org/ml-normal-equation-in-linear-regression/\n",
    "reset_graph()\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data] # add bias for linear algorithm. x0=1\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype  = tf.float32, name = 'y') #reshape create column matrix\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval() # get out matrix of weight for linear regression\n",
    "sess.close()\n",
    "print(theta_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.69419202e+01]\n",
      " [ 4.36693293e-01]\n",
      " [ 9.43577803e-03]\n",
      " [-1.07322041e-01]\n",
      " [ 6.45065694e-01]\n",
      " [-3.97638942e-06]\n",
      " [-3.78654265e-03]\n",
      " [-4.21314378e-01]\n",
      " [-4.34513755e-01]]\n"
     ]
    }
   ],
   "source": [
    "# The same in pure numpy\n",
    "X = housing_data_plus_bias\n",
    "y = housing.target.reshape(-1, 1)\n",
    "theta_value_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "print(theta_value_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With gradient descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for gradient descent\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE 9.161541938781738\n",
      "Epoch 100, MSE 0.7145004272460938\n",
      "Epoch 200, MSE 0.5667048692703247\n",
      "Epoch 300, MSE 0.5555717945098877\n",
      "Epoch 400, MSE 0.5488111972808838\n",
      "Epoch 500, MSE 0.5436363220214844\n",
      "Epoch 600, MSE 0.5396291017532349\n",
      "Epoch 700, MSE 0.5365092158317566\n",
      "Epoch 800, MSE 0.5340677499771118\n",
      "Epoch 900, MSE 0.5321472883224487\n"
     ]
    }
   ],
   "source": [
    "# manually computing gradients\n",
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype = tf.float32, name = 'y')\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1, 1, seed = 42), name = 'theta') # initialize a node with random numbers and fixed shape\n",
    "y_pred = tf.matmul(X, theta, name = 'predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = 'mse') # just mean. 'reduce' in this finction from functional  programming style. Read more here: https://www.python-course.eu/lambda.php\n",
    "gradients = 2/m*tf.matmul(tf.transpose(X), error) # check formula here: https://towardsdatascience.com/gradient-descent-in-python-a0d07285742f # alternative: gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - learning_rate*gradients) # we can do a for-loop through this variable, reassign it\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch {}, MSE {}'.format(epoch, mse.eval()))\n",
    "#             print(error.eval().sum())\n",
    "        sess.run(training_op)        \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685523 ],\n",
       "       [ 0.8874027 ],\n",
       "       [ 0.14401656],\n",
       "       [-0.34770882],\n",
       "       [ 0.36178368],\n",
       "       [ 0.00393811],\n",
       "       [-0.04269556],\n",
       "       [-0.6614529 ],\n",
       "       [-0.6375279 ]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE 9.161541938781738\n",
      "Epoch 100, MSE 0.5305594801902771\n",
      "Epoch 200, MSE 0.5251553654670715\n",
      "Epoch 300, MSE 0.5244484543800354\n",
      "Epoch 400, MSE 0.5243411660194397\n",
      "Epoch 500, MSE 0.5243241786956787\n",
      "Epoch 600, MSE 0.5243214964866638\n",
      "Epoch 700, MSE 0.5243210792541504\n",
      "Epoch 800, MSE 0.5243210196495056\n",
      "Epoch 900, MSE 0.5243209600448608\n"
     ]
    }
   ],
   "source": [
    "# Using GradientDescentOptimizer\n",
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype = tf.float32, name = 'y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1, 1, seed = 42), name = 'theta') # initialize a node with random numbers and fixed shape\n",
    "y_pred = tf.matmul(X, theta, name = 'predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = 'mse')\n",
    "#----------------------\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learing_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "#----------------------\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch {}, MSE {}'.format(epoch, mse.eval()))\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685577 ],\n",
       "       [ 0.8296404 ],\n",
       "       [ 0.11875556],\n",
       "       [-0.2655667 ],\n",
       "       [ 0.30572918],\n",
       "       [-0.00450185],\n",
       "       [-0.03932704],\n",
       "       [-0.8998373 ],\n",
       "       [-0.87049514]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With batch gradient descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### In this example batch iterations leads to gradient explosion! ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)\n",
    "    indices = np.random.randint(m, size = batch_size)\n",
    "    X_batch = scaled_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 3\n",
    "learning_rate = 0.0001\n",
    "#-----------------------\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "#-----------------------\n",
    "\n",
    "#------------------------------\n",
    "X = tf.placeholder(tf.float32, shape = (None, n+1), name = 'X')\n",
    "y = tf.placeholder(tf.float32, shape = (None, 1), name = 'y')\n",
    "#-----------------------------\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1, 1, seed = 42), name = 'theta') # initialize a node with random numbers and fixed shape\n",
    "y_pred = tf.matmul(X, theta, name = 'predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = 'mse')\n",
    "#----------------------\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learing_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "#----------------------\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "#         if epoch % 100 == 0 and epoch!=0:\n",
    "#             print('Epoch {}, MSE {}'.format(epoch, mse.eval()))\n",
    "#----------------------\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict = {X: X_batch, y: y_batch})\n",
    "#---------------------\n",
    "    best_theta = theta.eval()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.2043988e+02],\n",
       "       [-7.0654650e+00],\n",
       "       [ 8.0287799e+02],\n",
       "       [ 6.5292413e+02],\n",
       "       [ 2.5552672e+02],\n",
       "       [ 2.3535125e+03],\n",
       "       [ 3.6404062e+04],\n",
       "       [-8.4642719e+02],\n",
       "       [-1.4592883e+03]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
