{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 5 RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gooogr/Coursera_Advanced_Machine_Learning/blob/master/1%20-%20Introduction%20to%20Deep%20Learning/Week_5_RNN_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Ozo7yYyNN0aa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "metadata": {
        "id": "2We2ZydXOCk5",
        "colab_type": "code",
        "outputId": "bdcb8970-ca94-43b3-8d3e-6eec495ab155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()\n",
        "\n",
        "# If you're using the old version of the course (check a path of notebook on Coursera, you'll see v1 or v2),\n",
        "# use setup_week2_old()."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2019-04-24 15:01:26--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-04-24 15:01:31 (84.9 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "TsmD20NMN0ac",
        "colab_type": "code",
        "outputId": "e608b53a-074d-4c19-c67f-ba524aab7151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "O3q54awhN0ae",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "VW1B7SKIN0af",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "j8KQ_f_IN0ah",
        "colab_type": "code",
        "outputId": "f5e777a9-b8b5-496e-ef26-640848d61b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "P2fa7dmNN0aj",
        "colab_type": "code",
        "outputId": "35be9378-2a39-4563-d85f-113d165a987d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "o000-FSlN0al",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "metadata": {
        "id": "wOV2mSWPQZEK",
        "colab_type": "code",
        "outputId": "c1b5b261-4a54-4c17-8d67-005fa52c4785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "symbol_list = {symbol for name in names for symbol in name}\n",
        "symbol_list = [start_token + pad_token] + list(symbol_list)\n",
        "len(symbol_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "d8Drq-uRSVRx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "VklRx2KSN0al",
        "colab_type": "code",
        "outputId": "5c0092f9-d232-4e8b-e2c7-d80a8191dfab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tokens = symbol_list ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rr7yGGOfN0an",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "DNYQziHAN0an",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "token_to_id = defaultdict(lambda:1,{token:i for i,token in enumerate(tokens)}) ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "ZmNo1TVsN0ap",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "FDF9Sk-TN0ar",
        "colab_type": "code",
        "outputId": "884ca0f4-25b5-40fe-9536-d195c1154887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[18 50  3 40 10 40 35 42  1]\n",
            " [18 19 42 13 37 51  1  1  1]\n",
            " [18 53 37 48 34 34 48 35  1]\n",
            " [18 19 48 13 23 40 15 15 35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lva4uKj5N0at",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "Q6zFvQ__N0au",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "L3k1mlf-N0az",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next =  Dense(rnn_num_units,activation='tanh')### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens,activation='softmax')### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "beRSUl1_N0a1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "R9-sgkKyN0a2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb, h_t])### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KtUMmmUUN0a3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "QQzbHvPNN0a4",
        "colab_type": "code",
        "outputId": "c51ce859-5db0-4013-93b0-2e4f2265125d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qCh3xHsSN0a5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "YJL-m-XTN0a6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cAqCxAyNN0a7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "rtXp20NBN0a8",
        "colab_type": "code",
        "outputId": "d2764846-1fa3-4f8b-bbfc-f5152ac3d992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss =  tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix,predictions_matrix))### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EeDZZ4M8N0a9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: training"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "A3g6fv64N0a-",
        "colab_type": "code",
        "outputId": "657cdb4e-8e03-4abb-9481-50b6407ac912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TdmixX1JN0bA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "Lia6WS72N0bB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "LjGz8Km6N0bE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "2voJilYjN0bI",
        "colab_type": "code",
        "outputId": "f8af9cdd-eb03-420e-9452-8c8ca2b3a46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " IlidhuHHHHHHHHH\n",
            " TelarilacHHHHHH\n",
            " EldanteHHHHHHHH\n",
            " KeynlemHHHHHHHH\n",
            " VackapHHHHHHHHH\n",
            " EdeineHHHHHHHHH\n",
            " OlalsHHHHHHHHHH\n",
            " BacinaHHHHHHHHH\n",
            " CelmerHHHHHHHHH\n",
            " PolsalaHHHHHHHH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "0Ny8ap4JN0bJ",
        "colab_type": "code",
        "outputId": "a60716c1-2611-48ee-e88d-bf350523003f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " TrumpaliHHHHHHH\n",
            " TrumpaHHHHHHHHH\n",
            " TrumponaHHHHHHH\n",
            " TrumpeteHHHHHHH\n",
            " TrumpyHHHHHHHHH\n",
            " TrumpennaHHHHHH\n",
            " TrumpineHHHHHHH\n",
            " TrumpeteHHHHHHH\n",
            " TrumpanttadHHHH\n",
            " TrumpyHHHHHHHHH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kqhbq7cMN0bL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "tR0PWno0N0bL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"PgNLyBJC6lMXzfVk\"\n",
        "COURSERA_EMAIL = \"gusarovga@ya.ru\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "gY0AkB5vN0bP",
        "colab_type": "code",
        "outputId": "6218a6b8-1e93-412a-db5c-14c75bad57ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xSPCfHZuN0bR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "PM9V9jmCN0bS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "LYC6WZRkN0bS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RhgqkdIzN0bT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "TKj9SFLdN0bU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "iXh-nSXQN0bV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}